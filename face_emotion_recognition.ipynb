{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FileDownloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is responsible for downloading files from the internet.\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "class FileDownloader:\n",
    "    def __init__(self, url, file_path):\n",
    "        self.url = url\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def download(self):\n",
    "        if not os.path.exists(self.file_path):\n",
    "            print(f\"Downloading {self.file_path}...\")\n",
    "            urllib.request.urlretrieve(self.url, self.file_path)\n",
    "            print(f\"{self.file_path} downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YoloDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is responsible for loading the YOLO model and detecting objects in frames.\n",
    "import cv2\n",
    "\n",
    "class YoloDetector:\n",
    "    def __init__(self, weights_path, cfg_path, names_path):\n",
    "        self.weights_path = weights_path\n",
    "        self.cfg_path = cfg_path\n",
    "        self.names_path = names_path\n",
    "        self.net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = self._get_output_layers()\n",
    "        self.classes = self._load_classes()\n",
    "\n",
    "    def _get_output_layers(self):\n",
    "        try:\n",
    "            return [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers().flatten()]\n",
    "        except AttributeError:\n",
    "            return [self.layer_names[i[0] - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "\n",
    "    def _load_classes(self):\n",
    "        with open(self.names_path, \"r\") as f:\n",
    "            return f.read().strip().split(\"\\n\")\n",
    "\n",
    "    def detect_objects(self, frame):\n",
    "        height, width, _ = frame.shape\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward(self.output_layers)\n",
    "\n",
    "        max_area = 0\n",
    "        best_face = None\n",
    "        best_box = None\n",
    "\n",
    "        for detection in detections:\n",
    "            for obj in detection:\n",
    "                scores = obj[5:]\n",
    "                class_id = scores.argmax()\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > 0.5 and self.classes[class_id] == \"person\":\n",
    "                    center_x = int(obj[0] * width)\n",
    "                    center_y = int(obj[1] * height)\n",
    "                    box_w = int(obj[2] * width)\n",
    "                    box_h = int(obj[3] * height)\n",
    "                    x = int(center_x - box_w / 2)\n",
    "                    y = int(center_y - box_h / 2)\n",
    "\n",
    "                    area = box_w * box_h\n",
    "\n",
    "                    if area > max_area:\n",
    "                        max_area = area\n",
    "                        best_face = frame[y:y + box_h, x:x + box_w]\n",
    "                        best_box = (x, y, box_w, box_h)\n",
    "\n",
    "        return best_face, best_box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmotionAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This class is responsible for analyzing emotions from the detected face using DeepFace.\n",
    "from deepface import DeepFace\n",
    "\n",
    "class EmotionAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def analyze(self, face):\n",
    "        try:\n",
    "            result = DeepFace.analyze(face, actions=['emotion'], enforce_detection=False)\n",
    "            return result[0]['dominant_emotion']\n",
    "        except Exception as e:\n",
    "            print(f\"Error in emotion detection: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VideoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is responsible for capturing video frames and displaying them.\n",
    "import cv2\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, video_source=0):\n",
    "        self.cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "    def capture_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        return frame\n",
    "\n",
    "    def release(self):\n",
    "        self.cap.release()\n",
    "\n",
    "    def display_frame(self, frame):\n",
    "        cv2.imshow(\"YOLO-based Real-time Emotion Detection\", frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Downloading for YOLO Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code downloads the necessary YOLO files (weights, config, and class names) if they are not already present.\n",
    "# URLs to download the necessary files\n",
    "yolo_weights_url = \"https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4-tiny.weights\"\n",
    "yolo_cfg_url = \"https://github.com/AlexeyAB/darknet/raw/master/cfg/yolov4-tiny.cfg\"\n",
    "coco_names_url = \"https://github.com/AlexeyAB/darknet/raw/master/data/coco.names\"\n",
    "\n",
    "# File paths\n",
    "weights_path = \"yolov4-tiny.weights\"\n",
    "cfg_path = \"yolov4-tiny.cfg\"\n",
    "names_path = \"coco.names\"\n",
    "\n",
    "# Download YOLO files if not already present\n",
    "FileDownloader(yolo_weights_url, weights_path).download()\n",
    "FileDownloader(yolo_cfg_url, cfg_path).download()\n",
    "FileDownloader(coco_names_url, names_path).download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n",
      "Error in emotion detection: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# This cell runs the main loop, which captures video, detects faces, analyzes emotions, and displays the results in real-time.\n",
    "def main():\n",
    "    # Initialize components\n",
    "    yolo_detector = YoloDetector(weights_path, cfg_path, names_path)\n",
    "    emotion_analyzer = EmotionAnalyzer()\n",
    "    video_processor = VideoProcessor()\n",
    "\n",
    "    while True:\n",
    "        frame = video_processor.capture_frame()\n",
    "        best_face, best_box = yolo_detector.detect_objects(frame)\n",
    "\n",
    "        if best_face is not None:\n",
    "            emotion = emotion_analyzer.analyze(best_face)\n",
    "            if emotion:\n",
    "                x, y, box_w, box_h = best_box\n",
    "                cv2.rectangle(frame, (x, y), (x + box_w, y + box_h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        video_processor.display_frame(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_processor.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
